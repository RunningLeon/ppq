{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import onnxruntime\n",
    "import time\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import CalibrationDataReader, create_calibrator, write_calibration_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(model_path, input_shape=(1,3,224,224), providers=['CPUExecutionProvider']):\n",
    "    sess_options = onnxruntime.SessionOptions()\n",
    "    session = onnxruntime.InferenceSession(model_path, sess_options, providers=providers)\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    total = 0.0\n",
    "    runs = 10\n",
    "    input_data = np.zeros(input_shape, np.float32)\n",
    "    # Warming up\n",
    "    _ = session.run([], {input_name: input_data})\n",
    "    for i in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        _ = session.run([], {input_name: input_data})\n",
    "        end = (time.perf_counter() - start) * 1000\n",
    "        total += end\n",
    "        print(f\"{end:.2f}ms\")\n",
    "    total /= runs\n",
    "    print(f\"Avg: {total:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.08ms\n",
      "10.72ms\n",
      "10.60ms\n",
      "10.51ms\n",
      "10.61ms\n",
      "10.46ms\n",
      "10.49ms\n",
      "10.50ms\n",
      "10.48ms\n",
      "10.57ms\n",
      "Avg: 10.60ms\n"
     ]
    }
   ],
   "source": [
    "fp32_file= '/home/PJLAB/maningsheng/workspace/mse/ppq/working/end2end.onnx'\n",
    "int8_file= '/home/PJLAB/maningsheng/workspace/mse/ppq/working/quantized-ort_oos_int8.onnx'\n",
    "benchmark(fp32_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 16:13:48.842808783 [I:onnxruntime:, inference_session.cc:331 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\n",
      "2022-11-15 16:13:48.842826819 [I:onnxruntime:, inference_session.cc:351 ConstructorCommon] Dynamic block base set to 0\n",
      "2022-11-15 16:13:48.857497700 [I:onnxruntime:, inference_session.cc:1327 Initialize] Initializing session.\n",
      "2022-11-15 16:13:48.857524073 [I:onnxruntime:, inference_session.cc:1364 Initialize] Adding default CPU execution provider.\n",
      "2022-11-15 16:13:48.857676550 [V:onnxruntime:, inference_session.cc:150 VerifyEachNodeIsAssignedToAnEp] Node placements\n",
      "2022-11-15 16:13:48.857681587 [V:onnxruntime:, inference_session.cc:152 VerifyEachNodeIsAssignedToAnEp] All nodes have been placed on [CPUExecutionProvider].\n",
      "2022-11-15 16:13:48.857747724 [V:onnxruntime:, session_state.cc:68 CreateGraphInfo] SaveMLValueNameIndexMapping\n",
      "2022-11-15 16:13:48.857771036 [V:onnxruntime:, session_state.cc:114 CreateGraphInfo] Done saving OrtValue mappings.\n",
      "2022-11-15 16:13:48.857903234 [I:onnxruntime:, session_state_utils.cc:140 SaveInitializedTensors] Saving initialized tensors.\n",
      "2022-11-15 16:13:48.874811071 [I:onnxruntime:, session_state_utils.cc:266 SaveInitializedTensors] Done saving initialized tensors\n",
      "2022-11-15 16:13:48.876002899 [I:onnxruntime:, inference_session.cc:1576 Initialize] Session successfully initialized.\n"
     ]
    }
   ],
   "source": [
    "model_path = '/data/mse/ppq/working/end2end.onnx'\n",
    "augmented_model_path = '/data/mse/ppq/working/end2end-ort-trt-int8.onnx'\n",
    "sess_options = onnxruntime.SessionOptions()\n",
    "providers=[\"TensorrtExecutionProvider\"]\n",
    "sess_options.log_severity_level = 0\n",
    "sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
    "session = onnxruntime.InferenceSession(model_path, sess_options=sess_options, providers=providers)\n",
    "\n",
    "# INT8 calibration setting\n",
    "calibration_table_generation_enable = True  # Enable/Disable INT8 calibration\n",
    "\n",
    "# TensorRT EP INT8 settings\n",
    "os.environ[\"ORT_TENSORRT_FP16_ENABLE\"] = \"1\"  # Enable FP16 precision\n",
    "os.environ[\"ORT_TENSORRT_INT8_ENABLE\"] = \"1\"  # Enable INT8 precision\n",
    "os.environ[\"ORT_TENSORRT_INT8_CALIBRATION_TABLE_NAME\"] = \"calibration.flatbuffers\"  # Calibration table name\n",
    "os.environ[\"ORT_TENSORRT_ENGINE_CACHE_ENABLE\"] = \"1\"  # Enable engine caching\n",
    "execution_provider = [\"TensorrtExecutionProvider\"]\n",
    "\n",
    "\n",
    "# Generate INT8 calibration table\n",
    "if calibration_table_generation_enable:\n",
    "    calibrator = create_calibrator(model_path, [], augmented_model_path=augmented_model_path)\n",
    "    calibrator.set_execution_providers([\"CUDAExecutionProvider\"])        \n",
    "    data_reader = ImageNetDataReader()q\n",
    "    calibrator.collect_data(data_reader)\n",
    "    write_calibration_table(calibrator.compute_range())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 19:53:50.360646059 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.385602139 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.405855643 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.425132687 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.442909269 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.460875825 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.479056812 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.493803559 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.509407053 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.525084677 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.540177392 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.555624893 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.572174153 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.592748711 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.614609925 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n",
      "2022-11-16 19:53:50.631455841 [I:onnxruntime:, sequential_executor.cc:176 Execute] Begin execution\n"
     ]
    }
   ],
   "source": [
    "inference_outputs_list = []\n",
    "for i in range(16):\n",
    "    inputs = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "    output = session.run(None, dict(input=inputs))\n",
    "    inference_outputs_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000), (1, 1000)]\n"
     ]
    }
   ],
   "source": [
    "print([i[0].shape for i in inference_outputs_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataReader(CalibrationDataReader):\n",
    "    def __init__(self):\n",
    "        self.num = 16\n",
    "        \n",
    "    def get_next(self):\n",
    "        if self.num > 0:\n",
    "            self.num -= 1\n",
    "            img = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
    "            return dict(input=img)\n",
    "        else:\n",
    "            return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mqbench]",
   "language": "python",
   "name": "conda-env-mqbench-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
